\documentclass[final,dvipsnames]{beamer}
\input{header.tex}


\title{We Reach AGI!!!}
\author{Pingbang Hu} % To add other authors, use \and
\institute{University of Illinois Urbana-Champaign}

\footercontent{\href{https://www.example.com}{https://www.example.com} \hfill NeurIPS 2030}


\logoleft{\includegraphics[height=4.2cm]{Figures/logo/NeurIPS.png}\hspace{1em}\includegraphics[height=4.2cm]{Figures/logo/QRCode.png}}
\logoright{\includegraphics[height=5.5cm]{Figures/logo/UIUC.png}}

\addbibresource{reference.bib}

\begin{document}

\begin{frame}[t]
	\begin{columns}[t]

		\begin{column}{\colwidth}

			\begin{block}{\textbf{Problem Formulation}: A Curious Little Problem}
				The goal of this work is to understand something interesting but possibly unnecessary. But don't worry---we'll formalize it:

				\begin{definition}[The Problem]
					Formally, this is the problem we're pretending is novel. It involves mysterious variables, vague assumptions, and a deep sense of academic urgency.
				\end{definition}

				Here's a visual representation, just to look professional:

				\begin{figure}[H]
					\centering
					\includegraphics{example-image-a}
					\caption{A figure. Definitely helps, right?}
				\end{figure}

				As you can see, this figure captures the essence of the problem.

				\begin{highlight}[Insightful Highlight Box]
					This box exists to draw your attention. What to? Not entirely sure. But it's highlighted, so it must be important.
				\end{highlight}

			\end{block}

			\begin{block}{\textbf{Existing Approaches}: A Brief Stroll Through Literature}
				A quick literature review to show we read a few papers:

				\begin{itemize}
					\item Classical physics seems somehow relevant~\cite{newton1726philosophiae}.
					\item Honestly, we just needed a second bullet point.
				\end{itemize}
			\end{block}

			\begin{block}{\textbf{Overview and Contributions}}
				This work marks a pivotal moment in the history of ML and AI:
				\begin{enumerate}
					\item A theoretical argument for why {\color{RedOrange}\textbf{AGI}} is inevitable.
					\item We actually build such a model with \(\approx \)\emph{one trillion} parameters.
					\item Empirical results showing perfect scores on this year's IMO (not even out).
				\end{enumerate}
			\end{block}

		\end{column}


		\begin{column}{\colwidth}

			\begin{block}{\textbf{Theoretical Results}: Unquestionable Mathematical Rigor}
				Now that we've stated the problem, let's prove some theorems. Or at least write some that look impressive:

				\begin{theorem}[AGI Emergence]
					If your model has at least \(10^{12}\) parameters and a sufficiently dramatic name, it will become sentient with probability \(\epsilon > 0\).
				\end{theorem}

				\begin{definition}[Superintelligence Gradient]
					The partial derivative of model confidence with respect to Twitter hype. Empirically observed to be strictly increasing.
				\end{definition}

				\begin{figure}[H]
					\centering
					\includegraphics[width=0.7\linewidth]{example-image-b}
					\caption{Evidence of emergent intelligence.}
				\end{figure}
			\end{block}

			\begin{block}{\textbf{Failed Approaches}: We Suffered So You Don't Have To}
				Naturally, we tried some things that didn't work:

				\begin{itemize}
					\item \textbf{Copying ChatGPT:} Ethically dubious, technically tempting.
					\item \textbf{Brute Force AGI:} Required more GPUs than the planet currently owns.
				\end{itemize}

				\begin{theorem}[Overfit Paradox]
					As model size increases, accuracy increases on everything except the test set.
				\end{theorem}
			\end{block}

		\end{column}

		\begin{column}{\colwidth}

			\begin{block}{\textbf{Proposed Method}: Definitely Not Just a Bigger Transformer}
				Our model is designed with scalability, explainability, and marketability in mind.

				\begin{definition}[Trillion-Parameter Transformer]
					A neural network so large, it requires its own power grid and a team of therapists.
				\end{definition}

				\begin{theorem}[Universal Solver]
					Given enough data and a sufficiently vague benchmark, our model achieves state-of-the-art on at least one metric.
				\end{theorem}

				\begin{highlight}[Core Insight]
					If you make the model big enough, you can always claim "emergent behavior."
				\end{highlight}
			\end{block}

			\begin{block}{\textbf{Experimental Results}: Trust Us, We Have Graphs}
				We tested our model on:

				\begin{itemize}
					\item IMO. We got a perfect score. Somehow.
					\item The Turing Test. The judges asked it for dating advice and were convinced.
					\item StackOverflow. It answered ``it depends'' with \(95\%\) accuracy.
				\end{itemize}

				\begin{figure}[H]
					\centering
					\includegraphics[width=0.4\linewidth]{example-image-c}
					\caption{Blue line = us. Orange line = others. Need we say more?}
				\end{figure}
			\end{block}

			\begin{block}{\textbf{Conclusions and Next Steps}}
				\begin{enumerate}
					\item Our method is clearly on track to surpass human intelligence.
					\item We're currently retraining it using only philosopher quotes.
					\item Future work: deploy model on Mars and let it evolve in isolation.
				\end{enumerate}

				\begin{highlight}[Final Thought]
					This project started as a joke. Now it's under review at NeurIPS.
				\end{highlight}
			\end{block}

			\vspace{-1em}

			\begin{beamercolorbox}[colsep*=0ex]{block body}
				\begin{adjustwidth}{1ex}{1ex}
					\setlength{\parskip}{1ex}
					\vskip-1ex

					\begin{center}\mbox{}\vspace{-\baselineskip}
						\setlength\bibitemsep{0pt}
						\printbibliography[heading=none]
					\end{center}

				\end{adjustwidth}
				\vskip1ex
			\end{beamercolorbox}

		\end{column}

	\end{columns}
\end{frame}

\end{document}